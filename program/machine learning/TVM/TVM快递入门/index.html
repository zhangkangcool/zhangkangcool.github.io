<!DOCTYPE html>
<html lang="en" data-bs-theme="light">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../../../img/favicon.ico">
        <title>TVM快递入门 - My Docs</title>
        <link href="../../../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../../../css/fontawesome.min.css" rel="stylesheet">
        <link href="../../../../css/brands.min.css" rel="stylesheet">
        <link href="../../../../css/solid.min.css" rel="stylesheet">
        <link href="../../../../css/v4-font-face.min.css" rel="stylesheet">
        <link href="../../../../css/base.css" rel="stylesheet">
        <link id="hljs-light" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" >
        <link id="hljs-dark" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github-dark.min.css" disabled>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="../../../..">My Docs</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar-collapse" aria-controls="navbar-collapse" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">

                    <ul class="nav navbar-nav ms-md-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-bs-toggle="modal" data-bs-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../Frame/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../%E5%88%9D%E8%AF%86TVM/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-bs-toggle="collapse" data-bs-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-body-tertiary">
        <ul class="nav flex-column">
            
            <li class="nav-item" data-bs-level="2"><a href="#tvm" class="nav-link">TVM可以做什么</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="2"><a href="#_1" class="nav-link">模型编译运行的基本步骤</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="2"><a href="#_2" class="nav-link">示例代码</a>
              <ul class="nav flex-column">
              </ul>
            </li>
            
            <li class="nav-item" data-bs-level="2"><a href="#tvm_1" class="nav-link">附: TVM框图和核心概念</a>
              <ul class="nav flex-column">
              </ul>
            </li>
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<p>TVM是一个端到端的机器学习编译框架，它的目标是优化机器学习模型让其高效运行在不同的硬件平台上。
它前端支持TensorFlow, Pytorch, MXNet, ONNX等几乎所有的主流框架。
它支持多种后端(CUDA,ROCm,Vulkan,Metal,OpenCL,LLVM,C,WASM)及不同的设备平台(GPU,CPU,FPGA及各种自定义NPU)。</p>
<p><img alt="img" src="https://pic2.zhimg.com/80/v2-5a0952080ba5970b0dfdbdd83b8cc98d_1440w.jpg" /></p>
<h2 id="tvm">TVM可以做什么</h2>
<ul>
<li><strong>作为使用者：</strong> 使用TVM导入训练好的模型，进行优化，编译到特定目标平台，运行模型</li>
<li><strong>作为开发者：</strong> 绝大部分使用者其实也是TVM的开发者。开发者使用TVM通常是为了支持新的硬件平台，为此除了添加新的后端，一般也需要配套扩展对应的算子以及调度策略等。</li>
</ul>
<h2 id="_1">模型编译运行的基本步骤</h2>
<p><img alt="img" src="https://pic4.zhimg.com/80/v2-19e309ea1d2513a83d86c3ebfc5aa377_1440w.png" /></p>
<p>\1. 导入其他框架的模型 2. 将该模型转换成Relay（TVM的高层级IR）. Relay支持特性： - 传统数据流式的表示 - 函数式语言风格的表示 - 两种风格的混合 Relay 能够进行图层次的优化 3. 将Relay转换成更细粒度的Tensor Expression(TE) Relay使用FuseOps 将模型划分成小的子图，在此过程中可以使用一些schedule原语进行优化（如tiling, vectorization, parallelization, unrolling, and fusion） TOPI包含一些预定义的常用Operator。</p>
<ol>
<li>搜索最佳调度策略（AutoTVM或AutoScheduler） -<strong>AutoTVM</strong>: 模板化的自动调优模块。 常用算子的搜索模板也在TOPI中提供. -<strong>AutoScheduler (a.k.a. Ansor)</strong>: 无模板的自动调优模块，自动生成搜索空间</li>
<li>选择模型编译的最优配置。 自动调优会生成JSON格式的优化记录.</li>
<li>编译生成Tensor IR (TVM的低层级IR，相对于Relay）。 TVM支持的后端包括:</li>
<li>LLVM, 通过它可以生成llvm支持的所有硬件如x86, ARM.</li>
<li>特定编译器，如NVCC, NVIDIA的编译器.</li>
<li>通过BYOC(Bring Your Own Codegen)框架实现</li>
<li>编译生成机器代码。 TVM可以将模型编译成可链接的对象模块来通过轻量级的运行时来运行。 它提供多种语言的支持。TVM也支持将模型和运行时统一打包。</li>
</ol>
<h2 id="_2">示例代码</h2>
<pre><code class="language-python">&quot;&quot;&quot;
使用TVM的python API来进行模型的编译、运行和优化
&quot;&quot;&quot;
import onnx
from tvm.contrib.download import download_testdata
from PIL import Image
import numpy as np
import tvm.relay as relay
import tvm
from tvm.contrib import graph_executor

###############################################################################
# 获取一个预训练的模型（使用了一个ONNX格式的模型）和测试图片
model_url = &quot;&quot;.join(
    [
        &quot;https://github.com/onnx/models/raw/&quot;,
        &quot;master/vision/classification/resnet/model/&quot;,
        &quot;resnet50-v2-7.onnx&quot;,
    ]
)

model_path = download_testdata(model_url, &quot;resnet50-v2-7.onnx&quot;, module=&quot;onnx&quot;)
onnx_model = onnx.load(model_path)
img_url = &quot;https://s3.amazonaws.com/model-server/inputs/kitten.jpg&quot;
img_path = download_testdata(img_url, &quot;imagenet_cat.png&quot;, module=&quot;data&quot;)
# Resize it to 224x224
resized_image = Image.open(img_path).resize((224, 224))
img_data = np.asarray(resized_image).astype(&quot;float32&quot;)
# Our input image is in HWC layout while ONNX expects CHW input, so convert the array
img_data = np.transpose(img_data, (2, 0, 1))
# Normalize according to the ImageNet input specification
imagenet_mean = np.array([0.485, 0.456, 0.406]).reshape((3, 1, 1))
imagenet_stddev = np.array([0.229, 0.224, 0.225]).reshape((3, 1, 1))
norm_img_data = (img_data / 255 - imagenet_mean) / imagenet_stddev
# Add the batch dimension, as we are expecting 4-dimensional input: NCHW.
img_data = np.expand_dims(norm_img_data, axis=0)

###############################################################################
# 使用Relay来编译模型
target = &quot;llvm&quot; 
input_name = &quot;data&quot;
shape_dict = {input_name: img_data.shape}
mod, params = relay.frontend.from_onnx(onnx_model, shape_dict)
with tvm.transform.PassContext(opt_level=3):
    lib = relay.build(mod, target=target, params=params)
dev = tvm.device(str(target), 0)
module = graph_executor.GraphModule(lib[&quot;default&quot;](dev))

######################################################################
# 使用TVM Runtime运行模型
dtype = &quot;float32&quot;
module.set_input(input_name, img_data)
module.run()
output_shape = (1, 1000)
tvm_output = module.get_output(0, tvm.nd.empty(output_shape)).numpy()
#～～～～～～～～～～～
# 评估基本的性能数据
import timeit
timing_number = 10
timing_repeat = 10
unoptimized = (
    np.array(timeit.Timer(lambda: module.run()).repeat(repeat=timing_repeat, number=timing_number)) * 1000 / timing_number
)
unoptimized = {
    &quot;mean&quot;: np.mean(unoptimized),
    &quot;median&quot;: np.median(unoptimized),
    &quot;std&quot;: np.std(unoptimized),
}
print(unoptimized)
#～～～～～～～～～～
# 后处理 
from scipy.special import softmax
# Download a list of labels
labels_url = &quot;https://s3.amazonaws.com/onnx-model-zoo/synset.txt&quot;
labels_path = download_testdata(labels_url, &quot;synset.txt&quot;, module=&quot;data&quot;)

with open(labels_path, &quot;r&quot;) as f:
    labels = [l.rstrip() for l in f]
# Open the output and read the output tensor
scores = softmax(tvm_output)
scores = np.squeeze(scores)
ranks = np.argsort(scores)[::-1]
for rank in ranks[0:5]:
    print(&quot;class='%s' with probability=%f&quot; % (labels[rank], scores[rank]))
#～～～～～～～～～～～
# 输出结果 
#     # class='n02123045 tabby, tabby cat' with probability=0.610553
#     # class='n02123159 tiger cat' with probability=0.367179
#     # class='n02124075 Egyptian cat' with probability=0.019365
#     # class='n02129604 tiger, Panthera tigris' with probability=0.001273
#     # class='n04040759 radiator' with probability=0.000261

################################################################################
# 使用autotvm来优化模型
import tvm.auto_scheduler as auto_scheduler
from tvm.autotvm.tuner import XGBTuner
from tvm import autotvm
#～～～～～～～～～～～
# 基本配置参数
number = 10 # 尝试的不同优化配置的数目
repeat = 1  # 每个配置重复测量的次数
min_repeat_ms = 0  # 最小运行时间，影响GPU精度调优，CPU设置为0
timeout = 10  # 超时时间
# create a TVM runner
runner = autotvm.LocalRunner(
    number=number,
    repeat=repeat,
    timeout=timeout,
    min_repeat_ms=min_repeat_ms,
    enable_cpu_cache_flush=True,
)
#～～～～～～～～～～～～
# 优化选项
# tuner: 这里使用xgboost作为优化算法
# trials：对于产品级的模型，trials推荐值为CPU 1500, GPU 3000-4000. 这个是模型和处理器相关的。
#         需要多花时间实验。这里作为简单测试，仅设置为10
# Tearly_stopping：尝试最小次数
# measure_option: 构建运行选项 
# tuning_records： 输出的优化记录文件
tuning_option = {
    &quot;tuner&quot;: &quot;xgb&quot;,
    &quot;trials&quot;: 10,
    &quot;early_stopping&quot;: 100,
    &quot;measure_option&quot;: autotvm.measure_option(
        builder=autotvm.LocalBuilder(build_func=&quot;default&quot;), runner=runner
    ),
    &quot;tuning_records&quot;: &quot;resnet-50-v2-autotuning.json&quot;,
}
# begin by extracting the taks from the onnx model
tasks = autotvm.task.extract_from_program(mod[&quot;main&quot;], target=target, params=params)
# Tune the extracted tasks sequentially.
for i, task in enumerate(tasks):
    prefix = &quot;[Task %2d/%2d] &quot; % (i + 1, len(tasks))
    tuner_obj = XGBTuner(task, loss_type=&quot;rank&quot;)
    tuner_obj.tune(
        n_trial=min(tuning_option[&quot;trials&quot;], len(task.config_space)),
        early_stopping=tuning_option[&quot;early_stopping&quot;],
        measure_option=tuning_option[&quot;measure_option&quot;],
        callbacks=[
            autotvm.callback.progress_bar(tuning_option[&quot;trials&quot;], prefix=prefix),
            autotvm.callback.log_to_file(tuning_option[&quot;tuning_records&quot;]),
        ],
    )
#～～～～～～～ 
# 输出：
#   # [Task  1/24]  Current/Best:   10.71/  21.08 GFLOPS | Progress: (60/1000) | 111.77 s Done.
#   # [Task  1/24]  Current/Best:    9.32/  24.18 GFLOPS | Progress: (192/1000) | 365.02 s Done.
#   # [Task  2/24]  Current/Best:   22.39/ 177.59 GFLOPS | Progress: (960/1000) | 976.17 s Done.
#   # [Task  3/24]  Current/Best:   32.03/ 153.34 GFLOPS | Progress: (800/1000) | 776.84 s Done.
#   ....
#   # [Task 24/24]  Current/Best:   25.03/ 146.14 GFLOPS | Progress: (1000/1000) | 1112.55 s Done.

################################################################################
# 编译优化后的模型
with autotvm.apply_history_best(tuning_option[&quot;tuning_records&quot;]):
    with tvm.transform.PassContext(opt_level=3, config={}):
        lib = relay.build(mod, target=target, params=params)

dev = tvm.device(str(target), 0)
module = graph_executor.GraphModule(lib[&quot;default&quot;](dev))

#～～～～～～～～～
# 校验优化模型的结果
dtype = &quot;float32&quot;
module.set_input(input_name, img_data)
module.run()
output_shape = (1, 1000)
tvm_output = module.get_output(0, tvm.nd.empty(output_shape)).numpy()

scores = softmax(tvm_output)
scores = np.squeeze(scores)
ranks = np.argsort(scores)[::-1]
for rank in ranks[0:5]:
    print(&quot;class='%s' with probability=%f&quot; % (labels[rank], scores[rank]))

#～～～～～～～～～
# 评估性能
import timeit
timing_number = 10
timing_repeat = 10
optimized = (
    np.array(timeit.Timer(lambda: module.run()).repeat(repeat=timing_repeat, number=timing_number)) * 1000 / timing_number
)
optimized = {&quot;mean&quot;: np.mean(optimized), &quot;median&quot;: np.median(optimized), &quot;std&quot;: np.std(optimized)}

print(&quot;optimized: %s&quot; % (optimized))
print(&quot;unoptimized: %s&quot; % (unoptimized))
</code></pre>
<h2 id="tvm_1">附: TVM框图和核心概念</h2>
<p><img alt="img" src="https://pic2.zhimg.com/80/v2-6b4b521a2f41bd6884508664047bdc3d_1440w.jpg" /></p>
<p>- Frontends: TVM支持的前端，对接各大深度学习框架 - IR: immediate representation, 编译器使用的中间表示数据结构，在TVM中有Relay和TIR两个不同抽象层次的IR。 - Relay: TVM中抽象程度较高的IR，可以通过不同深度学习框架前端转换对应的预训练模型 - TIR: Tensor-lever IR，相对于Relay，TIR更偏向于底层，可表示基本的数学运算，更易于底层硬件的优化 - TE: Tensor expression,TVM使用TE来定义计算、进行优化。TE使用函数式编程来描述计算，每个算子都能用TE来表示 - TOPI: TVM Operator Inventory, TVM中提供了numpy风格的高级抽象算子。TOPI中提供了针对主流平台(x86,ARM,CUDA,ROCm等)的神经网络常用算子实现。</p>
<ul>
<li>AutoTVM: TVM中模板化的自动优化方法，它通过提供调度模板，自动搜索模板中定义的参数空间来优化模型和计算。</li>
<li>AutoScheduler(Ansor): TVM中无模板的优化方法，和AutoTVM相比，它无需手动编写调度模板。</li>
<li>IRModule：它是TVM中表示IR的核心数据结构。我们可以通过调度原语(Schedule Primitives)和传递优化(Passes)对其进行变换(transform).</li>
<li>Pass：传递给IRModuel的变换和优化策略，比如常量折叠，算子融合，布局变换等等</li>
</ul>
<p>DSA</p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../../../../js/bootstrap.bundle.min.js"></script>
        <script>
            var base_url = "../../../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../../../js/base.js"></script>
        <script src="../../../../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
