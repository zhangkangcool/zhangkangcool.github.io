<!DOCTYPE html>
<html lang="en" data-bs-theme="light">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../../../../img/favicon.ico">
        <title>Relay到llvm ir 1 - My Docs</title>
        <link href="../../../../../css/bootstrap.min.css" rel="stylesheet">
        <link href="../../../../../css/fontawesome.min.css" rel="stylesheet">
        <link href="../../../../../css/brands.min.css" rel="stylesheet">
        <link href="../../../../../css/solid.min.css" rel="stylesheet">
        <link href="../../../../../css/v4-font-face.min.css" rel="stylesheet">
        <link href="../../../../../css/base.css" rel="stylesheet">
        <link id="hljs-light" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github.min.css" >
        <link id="hljs-dark" rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/styles/github-dark.min.css" disabled>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/11.8.0/highlight.min.js"></script>
        <script>hljs.highlightAll();</script> 
    </head>

    <body>
        <div class="navbar fixed-top navbar-expand-lg navbar-dark bg-primary">
            <div class="container">
                <a class="navbar-brand" href="../../../../..">My Docs</a>
                <!-- Expander button -->
                <button type="button" class="navbar-toggler" data-bs-toggle="collapse" data-bs-target="#navbar-collapse" aria-controls="navbar-collapse" aria-expanded="false" aria-label="Toggle navigation">
                    <span class="navbar-toggler-icon"></span>
                </button>

                <!-- Expanded navigation -->
                <div id="navbar-collapse" class="navbar-collapse collapse">

                    <ul class="nav navbar-nav ms-md-auto">
                        <li class="nav-item">
                            <a href="#" class="nav-link" data-bs-toggle="modal" data-bs-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li class="nav-item">
                                <a rel="prev" href="../Relay%20IR/" class="nav-link">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li class="nav-item">
                                <a rel="next" href="../relay%E5%88%B0llvm%20ir%202/" class="nav-link">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
            <div class="row">
                    <div class="col-md-3"><div class="navbar-expand-md bs-sidebar hidden-print affix" role="complementary">
    <div class="navbar-header">
        <button type="button" class="navbar-toggler collapsed" data-bs-toggle="collapse" data-bs-target="#toc-collapse" title="Table of Contents">
            <span class="fa fa-angle-down"></span>
        </button>
    </div>

    
    <div id="toc-collapse" class="navbar-collapse collapse card bg-body-tertiary">
        <ul class="nav flex-column">
        </ul>
    </div>
</div></div>
                    <div class="col-md-9" role="main">

<p>本文在tvm 0.7.dev.1 源码上进行分析。</p>
<p>起点是官网文档的第一个例子:</p>
<pre><code class="language-text">batch_size = 1
num_class = 1000
image_shape = (3, 224, 224)
data_shape = (batch_size,) + image_shape
out_shape = (batch_size, num_class)
mod, params = relay.testing.resnet.get_workload(num_layers=18, batch_size=batch_size, image_shape=image_shape)
opt_level = 3
#target = tvm.target.cuda()
target = tvm.target.create('llvm -mcpu=skylake-avx512')
with tvm.transform.PassContext(opt_level=opt_level):
        graph, lib, params = relay.build(mod, target, params=params)
print(lib.get_source()[:])
</code></pre>
<p>我做了微小的改动，使得程序会将生成的llvm ir打印出来，方便我们观察。运行命令是:</p>
<pre><code class="language-text">python tvm-test.py &gt; tvm-test.ll
</code></pre>
<p>生成的ir文件包含众多类型定义和函数，其中一个函数如下，看起来是正确生成了？</p>
<pre><code class="language-text">define dllexport i32 @fused_nn_contrib_conv2d_NCHWc(i8* noalias nocapture readonly, i8* noalias nocapture readonly, i32, i8* noalias nocapture readnone, i8* noalias nocapture readnone, i8* noalias nocapture readnone) local_unnamed_addr {
entry:
  %6 = icmp eq i32 %2, 3
  br i1 %6, label %assert_end, label %assert_fail, !prof !5

assert_fail:                                      ; preds = %entry
  %7 = load void (i8*)*, void (i8*)** @__TVMAPISetLastError, align 8, !tbaa !6
  tail call void %7(i8* getelementptr inbounds ([82 x i8], [82 x i8]* @.str, i64 0, i64 0))
  ret i32 -1

assert_end:                                       ; preds = %entry
  %8 = bitcast i8* %0 to %1**
  %9 = load %1*, %1** %8, align 8
  %10 = bitcast i8* %1 to i32*
  %11 = load i32, i32* %10, align 4, !tbaa !9
  %12 = getelementptr inbounds i8, i8* %0, i64 8
  %13 = bitcast i8* %12 to %1**
  %14 = load %1*, %1** %13, align 8
  %15 = getelementptr inbounds i8, i8* %1, i64 4
  %16 = bitcast i8* %15 to i32*
  %17 = load i32, i32* %16, align 4, !tbaa !23
  ...
</code></pre>
<p>开始正式研究源码。入口函数是relay.build，该函数定义在<strong>tvm/python/tvm/relay/buil-d_module.py:184</strong>, 省略不重要的代码，紧扣主线，该函数的末尾部分才真正进入代码生成环节:</p>
<pre><code class="language-text">def build(mod, target=None, target_host=None, params=None):    
    ...
    with tophub_context:
        bld_mod = BuildModule()
        graph_json, mod, params = bld_mod.build(mod, target, target_host, params)
    return graph_json, mod, params

class BuildModule(object):
    &quot;&quot;&quot;Build an IR module to run on TVM graph runtime. This class is used
    to expose the `RelayBuildModule` APIs implemented in C++.
    &quot;&quot;&quot;
    def __init__(self):
        self.mod = _build_module._BuildModule()
        self._get_graph_json = self.mod[&quot;get_graph_json&quot;]
        self._get_module = self.mod[&quot;get_module&quot;]
        self._build = self.mod[&quot;build&quot;]
        self._optimize = self.mod[&quot;optimize&quot;]
        self._set_params_func = self.mod[&quot;set_params&quot;]
        self._get_params_func = self.mod[&quot;get_params&quot;]

    def build(self, mod, target=None, target_host=None, params=None):
        target = _update_target(target)

        # Setup the params.
        if params:
            self._set_params(params)
        # Build the IR module
        self._build(mod, target, target_host)
        # Get artifacts
        graph_json = self.get_json()
        mod = self.get_module()
        params = self.get_params()

        return graph_json, mod, params
</code></pre>
<p>从该类的注释中可以看出，该类主要是封装了C++类RelayBuildModule, 实际上也是，经过各种转发后(关于ffi以及它具体如何实现转发的机制我不关心)，最终self.build调用的是C++代码<strong>RelayBuildModule::Build(src/relay/backend/<a href="https://link.zhihu.com/?target=http%3A//build_module.cc%3A224">http://build_module.cc:224</a>)</strong>, 以下是涉及到的创建，构建模块代码:</p>
<pre><code class="language-cpp">runtime::Module RelayBuildCreate() {
  auto exec = make_object&lt;RelayBuildModule&gt;();
  return runtime::Module(exec);
}

TVM_REGISTER_GLOBAL(&quot;relay.build_module._BuildModule&quot;).set_body([](TVMArgs args, TVMRetValue* rv) {
  *rv = RelayBuildCreate();
});

void Build(IRModule mod, const TargetsMap&amp; targets, const tvm::Target&amp; target_host) {
    targets_ = targets;
    target_host_ = target_host;
    BuildRelay(mod, params_);
}
</code></pre>
<p>也就是说是通过<strong>RelayBuildModule::BuildRelay(src/relay/backend/<a href="https://link.zhihu.com/?target=http%3A//build_modul-e.cc%3A417">http://build_modul-e.cc:417</a>)</strong>来最终完成代码生成的, 我逻辑地把该函数分两部分来分析，第一部分是生成计算图，第二部分是生成目标代码。其实我还没太搞懂计算图，topi, te, tir和relay ir的个中关系。:)</p>
<p>下面是BuildRelay的第一部分:</p>
<pre><code class="language-text">  void BuildRelay(IRModule relay_module,
                  const std::unordered_map&lt;std::string, tvm::runtime::NDArray&gt;&amp; params) {
    // Relay IRModule -&gt; IRModule optimizations.
    relay_module = Optimize(relay_module, targets_, params);
    // Get the updated function.
    auto func = Downcast&lt;Function&gt;(relay_module-&gt;Lookup(&quot;main&quot;));

    // Generate code for the updated function.
    graph_codegen_ = std::unique_ptr&lt;GraphCodegen&gt;(new GraphCodegen());
    graph_codegen_-&gt;Init(nullptr, targets_);
    graph_codegen_-&gt;Codegen(func);
    ...
 }
</code></pre>
<p>这里岔开一个题外话, 就是在Relay上做的优化，同LLVM IR的优化类似，通过Pass来完成的，而tvm中添加pass和运行pass的工作交给了<strong>RelayBuildModule::Optimize</strong>来完成, 该函数大致的行为如下，添加到pass_seqs的就是pass的实体，有兴趣可以去看看各个pass干了啥。</p>
<pre><code class="language-text">IRModule Optimize(IRModule relay_module, const TargetsMap&amp; targets,
                    const std::unordered_map&lt;std::string, runtime::NDArray&gt;&amp; params) {
    Array&lt;Pass&gt; pass_seqs;
    Array&lt;runtime::String&gt; entry_functions{&quot;main&quot;};
    pass_seqs.push_back(transform::RemoveUnusedFunctions(entry_functions));

    // Run all dialect legalization passes.
    pass_seqs.push_back(relay::qnn::transform::Legalize());

    // Legalize pass is restricted to homogeneous execution for now.
    if (targets.size() == 1) {
      pass_seqs.push_back(transform::Legalize());
    }
    pass_seqs.push_back(transform::EliminateCommonSubexpr(fskip));
    pass_seqs.push_back(transform::CombineParallelConv2D(3));
    pass_seqs.push_back(transform::CombineParallelDense(3));
    pass_seqs.push_back(transform::CombineParallelBatchMatmul(3));
    pass_seqs.push_back(transform::FoldConstant());
    pass_seqs.push_back(transform::FoldScaleAxis());
    pass_seqs.push_back(transform::CanonicalizeCast());
    pass_seqs.push_back(transform::CanonicalizeOps());

    // Alter layout transformation is only applied to homogeneous execution yet.
    if (targets.size() == 1) {
      pass_seqs.push_back(transform::AlterOpLayout());
    }

    // Fast math optimizations.
    pass_seqs.push_back(transform::FastMath());
    pass_seqs.push_back(transform::FoldConstant());

    // Create a sequential pass and perform optimizations.
    transform::Pass seq = transform::Sequential(pass_seqs);
    relay_module = seq(relay_module);
}
</code></pre>
<p>最后通过<strong>SequentialNode(src/ir/<a href="https://link.zhihu.com/?target=http%3A//transform.cc%3A209">http://transform.cc:209</a>)</strong>来运行这些passes, 见代码:</p>
<pre><code class="language-text">// TODO(zhiics): we currenlty only sequentially execute each pass in
// a Sequential without the consideration of their orders. The phase
// ordering problem needs to be handled in the future.
IRModule SequentialNode::operator()(IRModule mod, const PassContext&amp; pass_ctx) const {
  for (const Pass&amp; pass : passes) {
    CHECK(pass.defined()) &lt;&lt; &quot;Found undefined pass for optimization.&quot;;
    const PassInfo&amp; pass_info = pass-&gt;Info();
    if (!PassEnabled(pass_info)) continue;
    // resolve dependencies
    for (const auto&amp; it : pass_info-&gt;required) {
      mod = GetPass(it)(std::move(mod), pass_ctx);
    }
    mod = pass(std::move(mod), pass_ctx);
  }
  return mod;
}
</code></pre>
<p>就是一个简单的for循环，但是并不是每个添加的pass都会运行，是根据PassContext中设定优化级别(在本例中即opt_level的赋值)等决定的。比较有趣的地方是注释上说当前并未考虑各个pass之间的顺序，或许说的是可以通过排序省去不必要的pass运行，像llvm一样，并不是每个Transform pass都会对Analysis pass的结果造成影响，因而不必重新分析等等? 有时间俺可以试着搞搞看。</p></div>
            </div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script src="../../../../../js/bootstrap.bundle.min.js"></script>
        <script>
            var base_url = "../../../../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../../../../js/base.js"></script>
        <script src="../../../../../search/main.js"></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="searchModalLabel" aria-hidden="true">
    <div class="modal-dialog modal-lg">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="searchModalLabel">Search</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
                <p>From here you can search these documents. Enter your search terms below.</p>
                <form>
                    <div class="form-group">
                        <input type="search" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results" data-no-results-text="No results found"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="keyboardModalLabel" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <h4 class="modal-title" id="keyboardModalLabel">Keyboard Shortcuts</h4>
                <button type="button" class="btn-close" data-bs-dismiss="modal" aria-label="Close"></button>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
